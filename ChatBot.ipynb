{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19/07)2020\n",
    "# Francisco Dominguez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "#from nltk.stem import SnowballStemmer\n",
    "#stemmer = SnowballStemmer('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLPModel(object):\n",
    "    def __init__(self):\n",
    "        self.chatBot=None\n",
    "    def setChatBot(self,cb):\n",
    "        self.chatBot=cb\n",
    "class NLPANN(object):\n",
    "    pass\n",
    "class NLPANNkeras(NLPANN):\n",
    "    def __init__(self,nlpModel):\n",
    "        self.nlpModel=nlpModel\n",
    "        self.ann=None\n",
    "    def train(self,train_x,train_y):\n",
    "        self.ann = Sequential()\n",
    "        self.ann.add(Dense(25, input_dim=train_x.shape[1]))     # densidad de la primera capa de neurona y tipo de entrada\n",
    "        self.ann.add(Dropout(0.5))                                   # convierte a 0 la mitad de 1 en el entrenamiento\n",
    "        self.ann.add(Dense(25))                                      # densidad de la primera capa de neurona\n",
    "        self.ann.add(Dropout(0.5))                                   # convierte a 0 la mitad de 1 en el entrenamiento\n",
    "        self.ann.add(Dense(train_y.shape[1], activation='softmax'))  # densidad de la salida\n",
    "        self.ann.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        #self.ann.build()\n",
    "        self.ann.summary()\n",
    "        self.ann.fit(train_x, train_y, epochs=500, batch_size=8)   # entrena el modelo\n",
    "    def save(self,filename):\n",
    "        self.ann.save(filename)\n",
    "    def load(self,filename):\n",
    "        self.ann = load_model(filename)\n",
    "    def predict(self,sentenceBow):\n",
    "        p=self.ann.predict(np.reshape(sentenceBow,(1,-1)))\n",
    "        return p\n",
    "class NLPModelBoW(NLPModel):\n",
    "    def __init__(self):\n",
    "        # Bag of Words data\n",
    "        self.words=[]\n",
    "        self.classes=[]\n",
    "        self.documents=[]\n",
    "        self.ignore_words=['?']\n",
    "        # MLP data (this could be in a different object)\n",
    "        self.ann=NLPANNkeras(self)\n",
    "        self.train_x = []\n",
    "        self.train_y = []\n",
    "    # return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
    "    def clean_up_sentence(self,sentence):\n",
    "        # tokenize the pattern\n",
    "        sentence_words = nltk.word_tokenize(sentence)\n",
    "        # stem each word\n",
    "        sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
    "        return sentence_words\n",
    "    def bow(self,sentence, show_details=False):\n",
    "        # tokenize the pattern\n",
    "        sentence_words = self.clean_up_sentence(sentence)\n",
    "        # bag of words\n",
    "        bag = []\n",
    "        # create our bag of words array\n",
    "        for w in self.words:\n",
    "            bag.append(1) if w in sentence_words else bag.append(0)\n",
    "        return(np.array(bag))\n",
    "    def buildData(self):\n",
    "        self.buildBowData()\n",
    "        self.buildTrainingData()\n",
    "    def buildBowData(self):\n",
    "        self.words=[]\n",
    "        self.classes=[]\n",
    "        self.documents=[]\n",
    "        for intent in self.chatBot.intents:\n",
    "            for pattern in intent.patterns:\n",
    "                # tokenize each word in the sentence\n",
    "                w = nltk.word_tokenize(pattern)\n",
    "                # add to our words list\n",
    "                self.words.extend(w)\n",
    "                # add to documents in our corpus\n",
    "                self.documents.append((pattern, intent.name))\n",
    "                # add to our classes list\n",
    "                if intent.name not in self.classes:\n",
    "                    self.classes.append(intent.name)\n",
    "        # stem and lower each word and remove duplicates\n",
    "        self.words = [stemmer.stem(w.lower()) for w in self.words if w not in self.ignore_words]\n",
    "        self.words = sorted(list(set(self.words)))\n",
    "\n",
    "        # remove duplicates\n",
    "        self.classes = sorted(list(set(self.classes)))\n",
    "\n",
    "        print (len(self.documents), \"documents\")\n",
    "        print (len(self.classes), \"classes\", self.classes)\n",
    "        print (len(self.words), \"unique stemmed words\", self.words)\n",
    "    def buildTrainingData(self):\n",
    "        # create our training data\n",
    "        training = []\n",
    "        output = []\n",
    "        # create an empty array for our output\n",
    "        output_empty = [0] * len(self.classes)\n",
    "\n",
    "        # training set, bag of words for each sentence\n",
    "        x=[]\n",
    "        y=[]\n",
    "        for doc in self.documents:\n",
    "            # initialize our bag of words\n",
    "            bag = self.bow(doc[0])\n",
    "            x.append(bag)\n",
    "            # output is a '0' for each tag and '1' for current tag\n",
    "            output_row = list(output_empty)\n",
    "            output_row[self.classes.index(doc[1])] = 1\n",
    "            y.append(output_row)\n",
    "        # shuffle our features and turn into np.array\n",
    "        random.shuffle(training)\n",
    "        training = np.array(training)\n",
    "        print(training.shape)\n",
    "\n",
    "        # create train data\n",
    "        self.train_x = np.array(x)\n",
    "        self.train_y = np.array(y)\n",
    "    def train(self):\n",
    "        self.ann.train(self.train_x,self.train_y)\n",
    "    def save(self):\n",
    "        # save all of our data structures\n",
    "        data={}\n",
    "        data['words']    =self.words \n",
    "        data['classes']  =self.classes \n",
    "        data['documents']=self.documents \n",
    "        data['train_x']  =self.train_x \n",
    "        data['train_y']  =self.train_y\n",
    "        pickle.dump( data, open( os.path.join('./',self.chatBot.name+\".pk\"), \"wb\" ) )\n",
    "        self.ann.save(os.path.join('./',self.chatBot.name+'.h5'))    # guarda el modelo\n",
    "    def load(self):\n",
    "        data = pickle.load( open( os.path.join('./',self.chatBot.name+\".pk\"), \"rb\" ) )\n",
    "        self.words     = data['words']\n",
    "        self.classes   = data['classes']\n",
    "        self.documents = data['documents']\n",
    "        self.train_x   = np.array(data['train_x'])\n",
    "        self.train_y   = np.array(data['train_y'])\n",
    "        self.ann.load(os.path.join('./',self.chatBot.name+'.h5'))\n",
    "    def predictClass(self,sentence):\n",
    "        sentenceBow=self.bow(sentence)\n",
    "        p=self.ann.predict(sentenceBow)\n",
    "        idClass=np.argmax(p)\n",
    "        pClass=np.max(p)\n",
    "        className=self.classes[idClass]\n",
    "        return className,idClass,pClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Intent(object):\n",
    "    def __init__(self):\n",
    "        self.name=\"\"\n",
    "        self.patterns=[]\n",
    "        self.responses=[]\n",
    "        self.action=None\n",
    "    def fromJsonData(self,intent):\n",
    "        self.patterns =[]\n",
    "        self.responses=[]\n",
    "        self.name=intent['tag']\n",
    "        for pattern in intent['patterns']:\n",
    "            self.patterns.append(pattern)\n",
    "        for response in intent['responses']:\n",
    "            self.responses.append(response)\n",
    "        #self.action=intent['action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatBot(object):\n",
    "    def __init__(self,name):\n",
    "        self.name=name\n",
    "        self.intents=[]\n",
    "        self.model=NLPModelBoW()\n",
    "        self.model.setChatBot(self)\n",
    "        #TODO: refactor this\n",
    "        self.loadJson()\n",
    "        self.model.load()\n",
    "    def loadJson(self):\n",
    "        self.intents=[]\n",
    "        with open(os.path.join('./',self.name+'.json')) as json_data:\n",
    "            intents = json.load(json_data)\n",
    "        # loop through each sentence in our intents patterns\n",
    "        for intent in intents['intents']:\n",
    "            iobj=Intent()\n",
    "            iobj.fromJsonData(intent)\n",
    "            self.intents.append(iobj)\n",
    "        self.model.buildData()\n",
    "    def chooseRandom(self,responses):\n",
    "        sizeResponses=len(responses)\n",
    "        chooseIdResponse=random.randint(0,sizeResponses-1)\n",
    "        return responses[chooseIdResponse]\n",
    "    def chooseResponse(self,predictedIntent):\n",
    "        for intent in self.intents:\n",
    "            if intent.name==predictedIntent:\n",
    "                return self.chooseRandom(intent.responses)\n",
    "    def chat(self,sentence):\n",
    "        cn,idc,pc=self.model.predictClass(sentence)\n",
    "        print(idc,cn,pc)\n",
    "        if pc<0.55:\n",
    "            return self.chooseRandom([\"I don't understand your sentence.\",\n",
    "                                 \"What do you mean?\",\n",
    "                                 \"Could you please repeat with other words?\"]),\"do not understand\"\n",
    "        return self.chooseResponse(cn),cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatBotEngine(object):\n",
    "    def __init__(self):\n",
    "        self.currentChatBot=ChatBot('intents')\n",
    "        self.currentIntent=\"None\"\n",
    "    def getInput(self):\n",
    "        return input('Ready: ')\n",
    "    def setOutput(self,response):\n",
    "        print(response)\n",
    "    def run(self):\n",
    "        while self.currentIntent!=\"goodbye\":\n",
    "            sentence=self.getInput()\n",
    "            response,intent=self.currentChatBot.chat(sentence)\n",
    "            self.currentIntent=intent\n",
    "            self.setOutput(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are analogous to winget for GUI\n",
    "class Chatget(object):\n",
    "    pass\n",
    "# This is analogous to desktop GUI\n",
    "class ChatDesktop(ChatBot):\n",
    "    pass\n",
    "# A chatbot to build or modify other chatbots\n",
    "class MetaChatBot(ChatBot):\n",
    "    pass\n",
    "# Detect prediction error an improve the model of chatbots\n",
    "class ChatLearner(ChatBot):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 documents\n",
      "9 classes ['goodbye', 'greeting', 'hours', 'mopeds', 'opentoday', 'payments', 'rental', 'thanks', 'today']\n",
      "48 unique stemmed words [\"'d\", \"'s\", 'a', 'acceiv', 'anyon', 'ar', 'bye', 'can', 'card', 'cash', 'credit', 'day', 'do', 'doe', 'good', 'goodby', 'hav', 'hello', 'help', 'hi', 'hour', 'how', 'i', 'is', 'kind', 'lat', 'lik', 'mastercard', 'mop', 'of', 'on', 'op', 'rent', 'see', 'tak', 'thank', 'that', 'ther', 'thi', 'to', 'today', 'we', 'what', 'when', 'which', 'work', 'yo', 'you']\n",
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "cb=ChatBot('intents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', 'How are you', 'Is anyone there?', 'Hello', 'Good day']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb.intents[0].patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "test=cb.model.bow('Which mopeds do you have for sales?')\n",
    "print(test.shape)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 48)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb.model.train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 9)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb.model.train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 hours 0.98776114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"We're open every day 9am-9pm\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb.chat('Are you open now?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 25)                1225      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 9)                 234       \n",
      "=================================================================\n",
      "Total params: 2,109\n",
      "Trainable params: 2,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 27 samples\n",
      "Epoch 1/500\n",
      "27/27 [==============================] - 0s 10ms/sample - loss: 2.3469 - accuracy: 0.2222\n",
      "Epoch 2/500\n",
      "27/27 [==============================] - 0s 302us/sample - loss: 2.3515 - accuracy: 0.0741\n",
      "Epoch 3/500\n",
      "27/27 [==============================] - 0s 343us/sample - loss: 2.5415 - accuracy: 0.1481\n",
      "Epoch 4/500\n",
      "27/27 [==============================] - 0s 356us/sample - loss: 2.2139 - accuracy: 0.1111\n",
      "Epoch 5/500\n",
      "27/27 [==============================] - 0s 353us/sample - loss: 2.2539 - accuracy: 0.1852\n",
      "Epoch 6/500\n",
      "27/27 [==============================] - 0s 379us/sample - loss: 2.1532 - accuracy: 0.2222\n",
      "Epoch 7/500\n",
      "27/27 [==============================] - 0s 344us/sample - loss: 2.4660 - accuracy: 0.1481\n",
      "Epoch 8/500\n",
      "27/27 [==============================] - 0s 352us/sample - loss: 2.4304 - accuracy: 0.1111\n",
      "Epoch 9/500\n",
      "27/27 [==============================] - 0s 357us/sample - loss: 2.2376 - accuracy: 0.2222\n",
      "Epoch 10/500\n",
      "27/27 [==============================] - 0s 371us/sample - loss: 2.2690 - accuracy: 0.1481\n",
      "Epoch 11/500\n",
      "27/27 [==============================] - 0s 393us/sample - loss: 2.1809 - accuracy: 0.2593\n",
      "Epoch 12/500\n",
      "27/27 [==============================] - 0s 359us/sample - loss: 2.0862 - accuracy: 0.2963\n",
      "Epoch 13/500\n",
      "27/27 [==============================] - 0s 349us/sample - loss: 2.0979 - accuracy: 0.2593\n",
      "Epoch 14/500\n",
      "27/27 [==============================] - 0s 359us/sample - loss: 1.9276 - accuracy: 0.2593\n",
      "Epoch 15/500\n",
      "27/27 [==============================] - 0s 345us/sample - loss: 2.0978 - accuracy: 0.1852\n",
      "Epoch 16/500\n",
      "27/27 [==============================] - 0s 365us/sample - loss: 2.0052 - accuracy: 0.3333\n",
      "Epoch 17/500\n",
      "27/27 [==============================] - 0s 349us/sample - loss: 2.2229 - accuracy: 0.0741\n",
      "Epoch 18/500\n",
      "27/27 [==============================] - 0s 366us/sample - loss: 2.0171 - accuracy: 0.2963\n",
      "Epoch 19/500\n",
      "27/27 [==============================] - 0s 370us/sample - loss: 2.1274 - accuracy: 0.2222\n",
      "Epoch 20/500\n",
      "27/27 [==============================] - 0s 365us/sample - loss: 2.1507 - accuracy: 0.3333\n",
      "Epoch 21/500\n",
      "27/27 [==============================] - 0s 352us/sample - loss: 1.9694 - accuracy: 0.2963\n",
      "Epoch 22/500\n",
      "27/27 [==============================] - 0s 366us/sample - loss: 1.9432 - accuracy: 0.3333\n",
      "Epoch 23/500\n",
      "27/27 [==============================] - 0s 360us/sample - loss: 2.0215 - accuracy: 0.2222\n",
      "Epoch 24/500\n",
      "27/27 [==============================] - 0s 412us/sample - loss: 1.8402 - accuracy: 0.4074\n",
      "Epoch 25/500\n",
      "27/27 [==============================] - 0s 342us/sample - loss: 2.2654 - accuracy: 0.1481\n",
      "Epoch 26/500\n",
      "27/27 [==============================] - 0s 383us/sample - loss: 1.8665 - accuracy: 0.3333\n",
      "Epoch 27/500\n",
      "27/27 [==============================] - 0s 391us/sample - loss: 1.9691 - accuracy: 0.2593\n",
      "Epoch 28/500\n",
      "27/27 [==============================] - 0s 334us/sample - loss: 1.8453 - accuracy: 0.2963\n",
      "Epoch 29/500\n",
      "27/27 [==============================] - 0s 385us/sample - loss: 1.8588 - accuracy: 0.1481\n",
      "Epoch 30/500\n",
      "27/27 [==============================] - 0s 406us/sample - loss: 1.6952 - accuracy: 0.4074\n",
      "Epoch 31/500\n",
      "27/27 [==============================] - 0s 378us/sample - loss: 1.7537 - accuracy: 0.4444\n",
      "Epoch 32/500\n",
      "27/27 [==============================] - 0s 399us/sample - loss: 1.8974 - accuracy: 0.2593\n",
      "Epoch 33/500\n",
      "27/27 [==============================] - 0s 392us/sample - loss: 1.6383 - accuracy: 0.5185\n",
      "Epoch 34/500\n",
      "27/27 [==============================] - 0s 375us/sample - loss: 1.8370 - accuracy: 0.3333\n",
      "Epoch 35/500\n",
      "27/27 [==============================] - 0s 339us/sample - loss: 1.9278 - accuracy: 0.2963\n",
      "Epoch 36/500\n",
      "27/27 [==============================] - 0s 363us/sample - loss: 1.8845 - accuracy: 0.3333\n",
      "Epoch 37/500\n",
      "27/27 [==============================] - 0s 390us/sample - loss: 1.6904 - accuracy: 0.4815\n",
      "Epoch 38/500\n",
      "27/27 [==============================] - 0s 384us/sample - loss: 1.7264 - accuracy: 0.4815\n",
      "Epoch 39/500\n",
      "27/27 [==============================] - 0s 347us/sample - loss: 1.7106 - accuracy: 0.4444\n",
      "Epoch 40/500\n",
      "27/27 [==============================] - 0s 388us/sample - loss: 1.6477 - accuracy: 0.5556\n",
      "Epoch 41/500\n",
      "27/27 [==============================] - 0s 356us/sample - loss: 1.7786 - accuracy: 0.2593\n",
      "Epoch 42/500\n",
      "27/27 [==============================] - 0s 320us/sample - loss: 1.7335 - accuracy: 0.3333\n",
      "Epoch 43/500\n",
      "27/27 [==============================] - 0s 354us/sample - loss: 1.3995 - accuracy: 0.6667\n",
      "Epoch 44/500\n",
      "27/27 [==============================] - 0s 400us/sample - loss: 1.4332 - accuracy: 0.6667\n",
      "Epoch 45/500\n",
      "27/27 [==============================] - 0s 333us/sample - loss: 1.5914 - accuracy: 0.5185\n",
      "Epoch 46/500\n",
      "27/27 [==============================] - 0s 374us/sample - loss: 1.5805 - accuracy: 0.5556\n",
      "Epoch 47/500\n",
      "27/27 [==============================] - 0s 420us/sample - loss: 1.5872 - accuracy: 0.3704\n",
      "Epoch 48/500\n",
      "27/27 [==============================] - 0s 394us/sample - loss: 1.4507 - accuracy: 0.5185\n",
      "Epoch 49/500\n",
      "27/27 [==============================] - 0s 426us/sample - loss: 1.5774 - accuracy: 0.5185\n",
      "Epoch 50/500\n",
      "27/27 [==============================] - 0s 452us/sample - loss: 1.7795 - accuracy: 0.3704\n",
      "Epoch 51/500\n",
      "27/27 [==============================] - 0s 359us/sample - loss: 1.5492 - accuracy: 0.5185\n",
      "Epoch 52/500\n",
      "27/27 [==============================] - 0s 392us/sample - loss: 1.4779 - accuracy: 0.6667\n",
      "Epoch 53/500\n",
      "27/27 [==============================] - 0s 364us/sample - loss: 1.5499 - accuracy: 0.5185\n",
      "Epoch 54/500\n",
      "27/27 [==============================] - 0s 350us/sample - loss: 1.3861 - accuracy: 0.6296\n",
      "Epoch 55/500\n",
      "27/27 [==============================] - 0s 462us/sample - loss: 1.5742 - accuracy: 0.4444\n",
      "Epoch 56/500\n",
      "27/27 [==============================] - 0s 481us/sample - loss: 1.5294 - accuracy: 0.6296\n",
      "Epoch 57/500\n",
      "27/27 [==============================] - 0s 465us/sample - loss: 1.4095 - accuracy: 0.6296\n",
      "Epoch 58/500\n",
      "27/27 [==============================] - 0s 428us/sample - loss: 1.2063 - accuracy: 0.5926\n",
      "Epoch 59/500\n",
      "27/27 [==============================] - 0s 458us/sample - loss: 1.3636 - accuracy: 0.5926\n",
      "Epoch 60/500\n",
      "27/27 [==============================] - 0s 461us/sample - loss: 1.5699 - accuracy: 0.4444\n",
      "Epoch 61/500\n",
      "27/27 [==============================] - 0s 500us/sample - loss: 1.3491 - accuracy: 0.6296\n",
      "Epoch 62/500\n",
      "27/27 [==============================] - 0s 425us/sample - loss: 1.5314 - accuracy: 0.4074\n",
      "Epoch 63/500\n",
      "27/27 [==============================] - 0s 430us/sample - loss: 1.5692 - accuracy: 0.5185\n",
      "Epoch 64/500\n",
      "27/27 [==============================] - 0s 467us/sample - loss: 1.3139 - accuracy: 0.5556\n",
      "Epoch 65/500\n",
      "27/27 [==============================] - 0s 446us/sample - loss: 1.3529 - accuracy: 0.6667\n",
      "Epoch 66/500\n",
      "27/27 [==============================] - 0s 449us/sample - loss: 1.3710 - accuracy: 0.5556\n",
      "Epoch 67/500\n",
      "27/27 [==============================] - 0s 448us/sample - loss: 1.2033 - accuracy: 0.6296\n",
      "Epoch 68/500\n",
      "27/27 [==============================] - 0s 518us/sample - loss: 1.1586 - accuracy: 0.7037\n",
      "Epoch 69/500\n",
      "27/27 [==============================] - 0s 426us/sample - loss: 1.0836 - accuracy: 0.7037\n",
      "Epoch 70/500\n",
      "27/27 [==============================] - 0s 469us/sample - loss: 1.1196 - accuracy: 0.7037\n",
      "Epoch 71/500\n",
      "27/27 [==============================] - 0s 443us/sample - loss: 1.0867 - accuracy: 0.5926\n",
      "Epoch 72/500\n",
      "27/27 [==============================] - 0s 444us/sample - loss: 1.2890 - accuracy: 0.5926\n",
      "Epoch 73/500\n",
      "27/27 [==============================] - 0s 413us/sample - loss: 1.1861 - accuracy: 0.5926\n",
      "Epoch 74/500\n",
      "27/27 [==============================] - 0s 457us/sample - loss: 1.2529 - accuracy: 0.6667\n",
      "Epoch 75/500\n",
      "27/27 [==============================] - 0s 435us/sample - loss: 1.2093 - accuracy: 0.6667\n",
      "Epoch 76/500\n",
      "27/27 [==============================] - 0s 369us/sample - loss: 1.1854 - accuracy: 0.6667\n",
      "Epoch 77/500\n",
      "27/27 [==============================] - 0s 388us/sample - loss: 1.1997 - accuracy: 0.5556\n",
      "Epoch 78/500\n",
      "27/27 [==============================] - 0s 555us/sample - loss: 1.1120 - accuracy: 0.7778\n",
      "Epoch 79/500\n",
      "27/27 [==============================] - 0s 384us/sample - loss: 1.1117 - accuracy: 0.6296\n",
      "Epoch 80/500\n",
      "27/27 [==============================] - 0s 356us/sample - loss: 1.1270 - accuracy: 0.6667\n",
      "Epoch 81/500\n",
      "27/27 [==============================] - 0s 366us/sample - loss: 1.1234 - accuracy: 0.6667\n",
      "Epoch 82/500\n",
      "27/27 [==============================] - 0s 359us/sample - loss: 1.1103 - accuracy: 0.7407\n",
      "Epoch 83/500\n",
      "27/27 [==============================] - 0s 362us/sample - loss: 1.0692 - accuracy: 0.7037\n",
      "Epoch 84/500\n",
      "27/27 [==============================] - 0s 387us/sample - loss: 1.0061 - accuracy: 0.7407\n",
      "Epoch 85/500\n",
      "27/27 [==============================] - 0s 354us/sample - loss: 1.1790 - accuracy: 0.6667\n",
      "Epoch 86/500\n",
      "27/27 [==============================] - 0s 391us/sample - loss: 1.1640 - accuracy: 0.6296\n",
      "Epoch 87/500\n",
      "27/27 [==============================] - 0s 386us/sample - loss: 0.9810 - accuracy: 0.6667\n",
      "Epoch 88/500\n",
      "27/27 [==============================] - 0s 369us/sample - loss: 0.9799 - accuracy: 0.7407\n",
      "Epoch 89/500\n",
      "27/27 [==============================] - 0s 360us/sample - loss: 1.0202 - accuracy: 0.6667\n",
      "Epoch 90/500\n",
      "27/27 [==============================] - 0s 360us/sample - loss: 1.0390 - accuracy: 0.6667\n",
      "Epoch 91/500\n",
      "27/27 [==============================] - 0s 346us/sample - loss: 1.0048 - accuracy: 0.6296\n",
      "Epoch 92/500\n",
      "27/27 [==============================] - 0s 403us/sample - loss: 0.9973 - accuracy: 0.7407\n",
      "Epoch 93/500\n",
      "27/27 [==============================] - 0s 428us/sample - loss: 0.8900 - accuracy: 0.8519\n",
      "Epoch 94/500\n",
      "27/27 [==============================] - 0s 354us/sample - loss: 1.1190 - accuracy: 0.5926\n",
      "Epoch 95/500\n",
      "27/27 [==============================] - 0s 392us/sample - loss: 1.0895 - accuracy: 0.7037\n",
      "Epoch 96/500\n",
      "27/27 [==============================] - 0s 392us/sample - loss: 0.9763 - accuracy: 0.6667\n",
      "Epoch 97/500\n",
      "27/27 [==============================] - 0s 365us/sample - loss: 0.9067 - accuracy: 0.6667\n",
      "Epoch 98/500\n",
      "27/27 [==============================] - 0s 388us/sample - loss: 0.8705 - accuracy: 0.8148\n",
      "Epoch 99/500\n",
      "27/27 [==============================] - 0s 389us/sample - loss: 1.0349 - accuracy: 0.7037\n",
      "Epoch 100/500\n",
      "27/27 [==============================] - 0s 357us/sample - loss: 0.8028 - accuracy: 0.8148\n",
      "Epoch 101/500\n",
      "27/27 [==============================] - 0s 458us/sample - loss: 0.8373 - accuracy: 0.7407\n",
      "Epoch 102/500\n",
      "27/27 [==============================] - 0s 397us/sample - loss: 1.0242 - accuracy: 0.6667\n",
      "Epoch 103/500\n",
      "27/27 [==============================] - 0s 372us/sample - loss: 0.7774 - accuracy: 0.8148\n",
      "Epoch 104/500\n",
      "27/27 [==============================] - 0s 421us/sample - loss: 1.1225 - accuracy: 0.7037\n",
      "Epoch 105/500\n",
      "27/27 [==============================] - 0s 382us/sample - loss: 1.1278 - accuracy: 0.5926\n",
      "Epoch 106/500\n",
      "27/27 [==============================] - 0s 366us/sample - loss: 0.8429 - accuracy: 0.8148\n",
      "Epoch 107/500\n",
      "27/27 [==============================] - 0s 387us/sample - loss: 1.0416 - accuracy: 0.7037\n",
      "Epoch 108/500\n",
      "27/27 [==============================] - 0s 403us/sample - loss: 0.9029 - accuracy: 0.7407\n",
      "Epoch 109/500\n",
      "27/27 [==============================] - 0s 349us/sample - loss: 0.9053 - accuracy: 0.8519\n",
      "Epoch 110/500\n",
      "27/27 [==============================] - 0s 388us/sample - loss: 0.9913 - accuracy: 0.7407\n",
      "Epoch 111/500\n",
      "27/27 [==============================] - 0s 513us/sample - loss: 0.5715 - accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "27/27 [==============================] - 0s 403us/sample - loss: 0.8044 - accuracy: 0.7407\n",
      "Epoch 113/500\n",
      "27/27 [==============================] - 0s 402us/sample - loss: 0.9327 - accuracy: 0.7407\n",
      "Epoch 114/500\n",
      "27/27 [==============================] - 0s 360us/sample - loss: 0.9821 - accuracy: 0.7037\n",
      "Epoch 115/500\n",
      "27/27 [==============================] - 0s 359us/sample - loss: 0.8710 - accuracy: 0.8148\n",
      "Epoch 116/500\n",
      "27/27 [==============================] - 0s 376us/sample - loss: 0.7594 - accuracy: 0.8519\n",
      "Epoch 117/500\n",
      "27/27 [==============================] - 0s 414us/sample - loss: 0.9527 - accuracy: 0.7778\n",
      "Epoch 118/500\n",
      "27/27 [==============================] - 0s 426us/sample - loss: 0.7381 - accuracy: 0.7407\n",
      "Epoch 119/500\n",
      "27/27 [==============================] - 0s 444us/sample - loss: 0.8778 - accuracy: 0.7407\n",
      "Epoch 120/500\n",
      "27/27 [==============================] - 0s 440us/sample - loss: 0.7236 - accuracy: 0.8519\n",
      "Epoch 121/500\n",
      "27/27 [==============================] - 0s 449us/sample - loss: 0.7267 - accuracy: 0.7778\n",
      "Epoch 122/500\n",
      "27/27 [==============================] - 0s 421us/sample - loss: 0.5583 - accuracy: 0.9259\n",
      "Epoch 123/500\n",
      "27/27 [==============================] - 0s 423us/sample - loss: 0.7194 - accuracy: 0.8889\n",
      "Epoch 124/500\n",
      "27/27 [==============================] - 0s 367us/sample - loss: 0.8453 - accuracy: 0.7407\n",
      "Epoch 125/500\n",
      "27/27 [==============================] - 0s 391us/sample - loss: 0.6113 - accuracy: 0.8889\n",
      "Epoch 126/500\n",
      "27/27 [==============================] - 0s 366us/sample - loss: 0.8040 - accuracy: 0.8519\n",
      "Epoch 127/500\n",
      "27/27 [==============================] - 0s 409us/sample - loss: 0.7116 - accuracy: 0.8148\n",
      "Epoch 128/500\n",
      "27/27 [==============================] - 0s 376us/sample - loss: 0.6929 - accuracy: 0.8889\n",
      "Epoch 129/500\n",
      "27/27 [==============================] - 0s 365us/sample - loss: 0.8163 - accuracy: 0.8519\n",
      "Epoch 130/500\n",
      "27/27 [==============================] - 0s 361us/sample - loss: 0.8284 - accuracy: 0.7037\n",
      "Epoch 131/500\n",
      "27/27 [==============================] - 0s 346us/sample - loss: 0.6321 - accuracy: 0.8148\n",
      "Epoch 132/500\n",
      "27/27 [==============================] - 0s 439us/sample - loss: 0.6275 - accuracy: 0.8889\n",
      "Epoch 133/500\n",
      "27/27 [==============================] - 0s 443us/sample - loss: 0.7038 - accuracy: 0.7037\n",
      "Epoch 134/500\n",
      "27/27 [==============================] - 0s 377us/sample - loss: 0.5842 - accuracy: 0.9259\n",
      "Epoch 135/500\n",
      "27/27 [==============================] - 0s 371us/sample - loss: 0.4864 - accuracy: 0.9630\n",
      "Epoch 136/500\n",
      "27/27 [==============================] - 0s 411us/sample - loss: 0.5703 - accuracy: 0.9259\n",
      "Epoch 137/500\n",
      "27/27 [==============================] - 0s 356us/sample - loss: 0.7883 - accuracy: 0.8519\n",
      "Epoch 138/500\n",
      "27/27 [==============================] - 0s 343us/sample - loss: 0.8170 - accuracy: 0.7407\n",
      "Epoch 139/500\n",
      "27/27 [==============================] - 0s 385us/sample - loss: 0.6018 - accuracy: 0.8519\n",
      "Epoch 140/500\n",
      "27/27 [==============================] - 0s 350us/sample - loss: 0.5510 - accuracy: 0.9259\n",
      "Epoch 141/500\n",
      "27/27 [==============================] - 0s 377us/sample - loss: 0.7105 - accuracy: 0.7778\n",
      "Epoch 142/500\n",
      "27/27 [==============================] - 0s 385us/sample - loss: 0.5581 - accuracy: 0.8148\n",
      "Epoch 143/500\n",
      "27/27 [==============================] - 0s 356us/sample - loss: 0.6039 - accuracy: 0.8519\n",
      "Epoch 144/500\n",
      "27/27 [==============================] - 0s 394us/sample - loss: 0.6980 - accuracy: 0.7778\n",
      "Epoch 145/500\n",
      "27/27 [==============================] - 0s 418us/sample - loss: 0.6149 - accuracy: 0.7037\n",
      "Epoch 146/500\n",
      "27/27 [==============================] - 0s 409us/sample - loss: 0.6130 - accuracy: 0.8889\n",
      "Epoch 147/500\n",
      "27/27 [==============================] - 0s 425us/sample - loss: 0.4181 - accuracy: 0.9259\n",
      "Epoch 148/500\n",
      "27/27 [==============================] - 0s 393us/sample - loss: 0.5370 - accuracy: 0.8889\n",
      "Epoch 149/500\n",
      "27/27 [==============================] - 0s 375us/sample - loss: 0.5904 - accuracy: 0.9259\n",
      "Epoch 150/500\n",
      "27/27 [==============================] - 0s 399us/sample - loss: 0.9981 - accuracy: 0.6296\n",
      "Epoch 151/500\n",
      "27/27 [==============================] - 0s 359us/sample - loss: 0.5963 - accuracy: 0.8889\n",
      "Epoch 152/500\n",
      "27/27 [==============================] - 0s 326us/sample - loss: 0.5416 - accuracy: 0.8889\n",
      "Epoch 153/500\n",
      "27/27 [==============================] - 0s 372us/sample - loss: 0.3849 - accuracy: 0.9630\n",
      "Epoch 154/500\n",
      "27/27 [==============================] - 0s 340us/sample - loss: 0.5048 - accuracy: 0.8889\n",
      "Epoch 155/500\n",
      "27/27 [==============================] - 0s 370us/sample - loss: 0.6086 - accuracy: 0.8519\n",
      "Epoch 156/500\n",
      "27/27 [==============================] - 0s 359us/sample - loss: 0.4780 - accuracy: 0.8889\n",
      "Epoch 157/500\n",
      "27/27 [==============================] - 0s 368us/sample - loss: 0.6878 - accuracy: 0.7778\n",
      "Epoch 158/500\n",
      "27/27 [==============================] - 0s 346us/sample - loss: 0.4702 - accuracy: 0.8519\n",
      "Epoch 159/500\n",
      "27/27 [==============================] - 0s 327us/sample - loss: 0.5888 - accuracy: 0.8148\n",
      "Epoch 160/500\n",
      "27/27 [==============================] - 0s 380us/sample - loss: 0.4881 - accuracy: 0.8148\n",
      "Epoch 161/500\n",
      "27/27 [==============================] - 0s 368us/sample - loss: 0.5971 - accuracy: 0.7407\n",
      "Epoch 162/500\n",
      "27/27 [==============================] - 0s 334us/sample - loss: 0.4867 - accuracy: 0.8889\n",
      "Epoch 163/500\n",
      "27/27 [==============================] - 0s 370us/sample - loss: 0.4803 - accuracy: 0.8519\n",
      "Epoch 164/500\n",
      "27/27 [==============================] - 0s 368us/sample - loss: 0.6682 - accuracy: 0.7778\n",
      "Epoch 165/500\n",
      "27/27 [==============================] - 0s 360us/sample - loss: 0.6431 - accuracy: 0.8148\n",
      "Epoch 166/500\n",
      "27/27 [==============================] - 0s 377us/sample - loss: 0.5957 - accuracy: 0.8519\n",
      "Epoch 167/500\n",
      "27/27 [==============================] - 0s 430us/sample - loss: 0.4953 - accuracy: 0.8519\n",
      "Epoch 168/500\n",
      "27/27 [==============================] - 0s 349us/sample - loss: 0.5627 - accuracy: 0.8148\n",
      "Epoch 169/500\n",
      "27/27 [==============================] - 0s 390us/sample - loss: 0.5372 - accuracy: 0.8889\n",
      "Epoch 170/500\n",
      "27/27 [==============================] - 0s 389us/sample - loss: 0.4632 - accuracy: 0.8889\n",
      "Epoch 171/500\n",
      "27/27 [==============================] - 0s 359us/sample - loss: 0.6654 - accuracy: 0.7778\n",
      "Epoch 172/500\n",
      "27/27 [==============================] - 0s 445us/sample - loss: 0.6135 - accuracy: 0.8889\n",
      "Epoch 173/500\n",
      "27/27 [==============================] - 0s 402us/sample - loss: 0.4234 - accuracy: 0.9259\n",
      "Epoch 174/500\n",
      "27/27 [==============================] - 0s 356us/sample - loss: 0.6112 - accuracy: 0.7778\n",
      "Epoch 175/500\n",
      "27/27 [==============================] - 0s 409us/sample - loss: 0.4680 - accuracy: 0.9259\n",
      "Epoch 176/500\n",
      "27/27 [==============================] - 0s 394us/sample - loss: 0.4538 - accuracy: 0.8889\n",
      "Epoch 177/500\n",
      "27/27 [==============================] - 0s 351us/sample - loss: 0.4241 - accuracy: 0.8519\n",
      "Epoch 178/500\n",
      "27/27 [==============================] - 0s 394us/sample - loss: 0.5129 - accuracy: 0.8519\n",
      "Epoch 179/500\n",
      "27/27 [==============================] - 0s 364us/sample - loss: 0.5063 - accuracy: 0.8889\n",
      "Epoch 180/500\n",
      "27/27 [==============================] - 0s 349us/sample - loss: 0.4623 - accuracy: 0.8889\n",
      "Epoch 181/500\n",
      "27/27 [==============================] - 0s 484us/sample - loss: 0.3214 - accuracy: 0.9259\n",
      "Epoch 182/500\n",
      "27/27 [==============================] - 0s 469us/sample - loss: 0.5730 - accuracy: 0.8148\n",
      "Epoch 183/500\n",
      "27/27 [==============================] - 0s 441us/sample - loss: 0.3596 - accuracy: 0.9259\n",
      "Epoch 184/500\n",
      "27/27 [==============================] - 0s 447us/sample - loss: 0.4181 - accuracy: 0.8519\n",
      "Epoch 185/500\n",
      "27/27 [==============================] - 0s 455us/sample - loss: 0.3726 - accuracy: 0.8889\n",
      "Epoch 186/500\n",
      "27/27 [==============================] - 0s 428us/sample - loss: 0.4817 - accuracy: 0.7778\n",
      "Epoch 187/500\n",
      "27/27 [==============================] - 0s 439us/sample - loss: 0.3927 - accuracy: 0.8889\n",
      "Epoch 188/500\n",
      "27/27 [==============================] - 0s 434us/sample - loss: 0.4335 - accuracy: 0.9259\n",
      "Epoch 189/500\n",
      "27/27 [==============================] - 0s 440us/sample - loss: 0.6572 - accuracy: 0.7778\n",
      "Epoch 190/500\n",
      "27/27 [==============================] - 0s 406us/sample - loss: 0.4462 - accuracy: 0.8889\n",
      "Epoch 191/500\n",
      "27/27 [==============================] - 0s 433us/sample - loss: 0.3581 - accuracy: 1.0000\n",
      "Epoch 192/500\n",
      "27/27 [==============================] - 0s 418us/sample - loss: 0.4397 - accuracy: 0.9259\n",
      "Epoch 193/500\n",
      "27/27 [==============================] - 0s 440us/sample - loss: 0.5286 - accuracy: 0.8148\n",
      "Epoch 194/500\n",
      "27/27 [==============================] - 0s 370us/sample - loss: 0.4912 - accuracy: 0.9259\n",
      "Epoch 195/500\n",
      "27/27 [==============================] - 0s 330us/sample - loss: 0.4142 - accuracy: 0.8889\n",
      "Epoch 196/500\n",
      "27/27 [==============================] - 0s 354us/sample - loss: 0.4140 - accuracy: 0.8889\n",
      "Epoch 197/500\n",
      "27/27 [==============================] - 0s 373us/sample - loss: 0.4769 - accuracy: 0.8148\n",
      "Epoch 198/500\n",
      "27/27 [==============================] - 0s 365us/sample - loss: 0.5762 - accuracy: 0.7778\n",
      "Epoch 199/500\n",
      "27/27 [==============================] - 0s 354us/sample - loss: 0.3955 - accuracy: 0.8889\n",
      "Epoch 200/500\n",
      "27/27 [==============================] - 0s 320us/sample - loss: 0.5833 - accuracy: 0.8519\n",
      "Epoch 201/500\n",
      "27/27 [==============================] - 0s 378us/sample - loss: 0.4426 - accuracy: 0.8889\n",
      "Epoch 202/500\n",
      "27/27 [==============================] - 0s 354us/sample - loss: 0.3144 - accuracy: 0.9630\n",
      "Epoch 203/500\n",
      "27/27 [==============================] - 0s 393us/sample - loss: 0.4632 - accuracy: 0.8889\n",
      "Epoch 204/500\n",
      "27/27 [==============================] - 0s 367us/sample - loss: 0.4135 - accuracy: 0.8889\n",
      "Epoch 205/500\n",
      "27/27 [==============================] - 0s 371us/sample - loss: 0.3996 - accuracy: 0.8889\n",
      "Epoch 206/500\n",
      "27/27 [==============================] - 0s 350us/sample - loss: 0.4533 - accuracy: 0.8889\n",
      "Epoch 207/500\n",
      "27/27 [==============================] - 0s 367us/sample - loss: 0.3446 - accuracy: 0.8889\n",
      "Epoch 208/500\n",
      "27/27 [==============================] - 0s 363us/sample - loss: 0.4028 - accuracy: 0.9259\n",
      "Epoch 209/500\n",
      "27/27 [==============================] - 0s 363us/sample - loss: 0.4056 - accuracy: 0.9259\n",
      "Epoch 210/500\n",
      "27/27 [==============================] - 0s 365us/sample - loss: 0.3994 - accuracy: 0.8889\n",
      "Epoch 211/500\n",
      "27/27 [==============================] - 0s 349us/sample - loss: 0.4525 - accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "27/27 [==============================] - 0s 409us/sample - loss: 0.3123 - accuracy: 0.9630\n",
      "Epoch 213/500\n",
      "27/27 [==============================] - 0s 400us/sample - loss: 0.2475 - accuracy: 0.9259\n",
      "Epoch 214/500\n",
      "27/27 [==============================] - 0s 347us/sample - loss: 0.2025 - accuracy: 0.9630\n",
      "Epoch 215/500\n",
      "27/27 [==============================] - 0s 369us/sample - loss: 0.4105 - accuracy: 0.9630\n",
      "Epoch 216/500\n",
      "27/27 [==============================] - 0s 381us/sample - loss: 0.6180 - accuracy: 0.8148\n",
      "Epoch 217/500\n",
      "27/27 [==============================] - 0s 358us/sample - loss: 0.2533 - accuracy: 0.9630\n",
      "Epoch 218/500\n",
      "27/27 [==============================] - 0s 414us/sample - loss: 0.3714 - accuracy: 0.9630\n",
      "Epoch 219/500\n",
      "27/27 [==============================] - 0s 377us/sample - loss: 0.4025 - accuracy: 0.8889\n",
      "Epoch 220/500\n",
      "27/27 [==============================] - 0s 384us/sample - loss: 0.3085 - accuracy: 0.9259\n",
      "Epoch 221/500\n",
      "27/27 [==============================] - 0s 365us/sample - loss: 0.3660 - accuracy: 0.8889\n",
      "Epoch 222/500\n",
      "27/27 [==============================] - 0s 327us/sample - loss: 0.2845 - accuracy: 0.9259\n",
      "Epoch 223/500\n",
      "27/27 [==============================] - 0s 382us/sample - loss: 0.5864 - accuracy: 0.7778\n",
      "Epoch 224/500\n",
      "27/27 [==============================] - 0s 383us/sample - loss: 0.3184 - accuracy: 0.8889\n",
      "Epoch 225/500\n",
      "27/27 [==============================] - 0s 407us/sample - loss: 0.4794 - accuracy: 0.8519\n",
      "Epoch 226/500\n",
      "27/27 [==============================] - 0s 388us/sample - loss: 0.5239 - accuracy: 0.7778\n",
      "Epoch 227/500\n",
      "27/27 [==============================] - 0s 367us/sample - loss: 0.5208 - accuracy: 0.8519\n",
      "Epoch 228/500\n",
      "27/27 [==============================] - 0s 367us/sample - loss: 0.2704 - accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "27/27 [==============================] - 0s 365us/sample - loss: 0.2251 - accuracy: 0.9259\n",
      "Epoch 230/500\n",
      "27/27 [==============================] - 0s 340us/sample - loss: 0.4008 - accuracy: 0.9259\n",
      "Epoch 231/500\n",
      "27/27 [==============================] - 0s 368us/sample - loss: 0.2752 - accuracy: 0.9630\n",
      "Epoch 232/500\n",
      "27/27 [==============================] - 0s 365us/sample - loss: 0.2604 - accuracy: 0.9259\n",
      "Epoch 233/500\n",
      "27/27 [==============================] - 0s 358us/sample - loss: 0.2602 - accuracy: 0.9259\n",
      "Epoch 234/500\n",
      "27/27 [==============================] - 0s 394us/sample - loss: 0.3542 - accuracy: 0.9259\n",
      "Epoch 235/500\n",
      "27/27 [==============================] - 0s 408us/sample - loss: 0.3444 - accuracy: 0.8889\n",
      "Epoch 236/500\n",
      "27/27 [==============================] - 0s 378us/sample - loss: 0.2674 - accuracy: 0.9259\n",
      "Epoch 237/500\n",
      "27/27 [==============================] - 0s 378us/sample - loss: 0.3182 - accuracy: 0.9259\n",
      "Epoch 238/500\n",
      "27/27 [==============================] - 0s 372us/sample - loss: 0.2206 - accuracy: 0.9259\n",
      "Epoch 239/500\n",
      "27/27 [==============================] - 0s 410us/sample - loss: 0.3051 - accuracy: 0.9259\n",
      "Epoch 240/500\n",
      "27/27 [==============================] - 0s 396us/sample - loss: 0.3275 - accuracy: 0.9259\n",
      "Epoch 241/500\n",
      "27/27 [==============================] - 0s 440us/sample - loss: 0.4011 - accuracy: 0.8519\n",
      "Epoch 242/500\n",
      "27/27 [==============================] - 0s 327us/sample - loss: 0.3937 - accuracy: 0.8889\n",
      "Epoch 243/500\n",
      "27/27 [==============================] - 0s 466us/sample - loss: 0.3027 - accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "27/27 [==============================] - 0s 393us/sample - loss: 0.3041 - accuracy: 0.9630\n",
      "Epoch 245/500\n",
      "27/27 [==============================] - 0s 357us/sample - loss: 0.2594 - accuracy: 0.9630\n",
      "Epoch 246/500\n",
      "27/27 [==============================] - 0s 339us/sample - loss: 0.2195 - accuracy: 0.9630\n",
      "Epoch 247/500\n",
      "27/27 [==============================] - 0s 359us/sample - loss: 0.1606 - accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "27/27 [==============================] - 0s 358us/sample - loss: 0.2396 - accuracy: 0.9259\n",
      "Epoch 249/500\n",
      "27/27 [==============================] - 0s 391us/sample - loss: 0.2659 - accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "27/27 [==============================] - 0s 343us/sample - loss: 0.3470 - accuracy: 0.8889\n",
      "Epoch 251/500\n",
      "27/27 [==============================] - 0s 366us/sample - loss: 0.2375 - accuracy: 0.9630\n",
      "Epoch 252/500\n",
      "27/27 [==============================] - 0s 417us/sample - loss: 0.2624 - accuracy: 0.9259\n",
      "Epoch 253/500\n",
      "27/27 [==============================] - 0s 431us/sample - loss: 0.3806 - accuracy: 0.8889\n",
      "Epoch 254/500\n",
      "27/27 [==============================] - 0s 428us/sample - loss: 0.3925 - accuracy: 0.9259\n",
      "Epoch 255/500\n",
      "27/27 [==============================] - 0s 360us/sample - loss: 0.1625 - accuracy: 0.9630\n",
      "Epoch 256/500\n",
      "27/27 [==============================] - 0s 420us/sample - loss: 0.3394 - accuracy: 0.9259\n",
      "Epoch 257/500\n",
      "27/27 [==============================] - 0s 422us/sample - loss: 0.3612 - accuracy: 0.8889\n",
      "Epoch 258/500\n",
      "27/27 [==============================] - 0s 414us/sample - loss: 0.3638 - accuracy: 0.8889\n",
      "Epoch 259/500\n",
      "27/27 [==============================] - 0s 434us/sample - loss: 0.1645 - accuracy: 0.9259\n",
      "Epoch 260/500\n",
      "27/27 [==============================] - 0s 434us/sample - loss: 0.3153 - accuracy: 0.8889\n",
      "Epoch 261/500\n",
      "27/27 [==============================] - 0s 413us/sample - loss: 0.3524 - accuracy: 0.8519\n",
      "Epoch 262/500\n",
      "27/27 [==============================] - 0s 437us/sample - loss: 0.3758 - accuracy: 0.8889\n",
      "Epoch 263/500\n",
      "27/27 [==============================] - 0s 419us/sample - loss: 0.2395 - accuracy: 0.9630\n",
      "Epoch 264/500\n",
      "27/27 [==============================] - 0s 437us/sample - loss: 0.3200 - accuracy: 0.9259\n",
      "Epoch 265/500\n",
      "27/27 [==============================] - 0s 490us/sample - loss: 0.2265 - accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "27/27 [==============================] - 0s 422us/sample - loss: 0.2284 - accuracy: 0.9259\n",
      "Epoch 267/500\n",
      "27/27 [==============================] - 0s 425us/sample - loss: 0.2700 - accuracy: 0.8889\n",
      "Epoch 268/500\n",
      "27/27 [==============================] - 0s 443us/sample - loss: 0.2237 - accuracy: 0.9259\n",
      "Epoch 269/500\n",
      "27/27 [==============================] - 0s 401us/sample - loss: 0.2881 - accuracy: 0.8889\n",
      "Epoch 270/500\n",
      "27/27 [==============================] - 0s 414us/sample - loss: 0.3243 - accuracy: 0.8519\n",
      "Epoch 271/500\n",
      "27/27 [==============================] - 0s 419us/sample - loss: 0.2744 - accuracy: 0.9259\n",
      "Epoch 272/500\n",
      "27/27 [==============================] - 0s 395us/sample - loss: 0.2183 - accuracy: 0.9259\n",
      "Epoch 273/500\n",
      "27/27 [==============================] - 0s 405us/sample - loss: 0.2008 - accuracy: 0.9630\n",
      "Epoch 274/500\n",
      "27/27 [==============================] - 0s 402us/sample - loss: 0.1959 - accuracy: 0.9259\n",
      "Epoch 275/500\n",
      "27/27 [==============================] - 0s 386us/sample - loss: 0.2825 - accuracy: 0.9259\n",
      "Epoch 276/500\n",
      "27/27 [==============================] - 0s 432us/sample - loss: 0.2386 - accuracy: 0.9630\n",
      "Epoch 277/500\n",
      "27/27 [==============================] - 0s 438us/sample - loss: 0.3021 - accuracy: 0.9259\n",
      "Epoch 278/500\n",
      "27/27 [==============================] - 0s 410us/sample - loss: 0.2610 - accuracy: 0.8889\n",
      "Epoch 279/500\n",
      "27/27 [==============================] - 0s 436us/sample - loss: 0.1611 - accuracy: 0.9630\n",
      "Epoch 280/500\n",
      "27/27 [==============================] - 0s 424us/sample - loss: 0.2597 - accuracy: 0.9630\n",
      "Epoch 281/500\n",
      "27/27 [==============================] - 0s 416us/sample - loss: 0.1621 - accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "27/27 [==============================] - 0s 433us/sample - loss: 0.3083 - accuracy: 0.9259\n",
      "Epoch 283/500\n",
      "27/27 [==============================] - 0s 407us/sample - loss: 0.1573 - accuracy: 0.9630\n",
      "Epoch 284/500\n",
      "27/27 [==============================] - 0s 419us/sample - loss: 0.2284 - accuracy: 0.9259\n",
      "Epoch 285/500\n",
      "27/27 [==============================] - 0s 440us/sample - loss: 0.1862 - accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "27/27 [==============================] - 0s 339us/sample - loss: 0.3306 - accuracy: 0.9630\n",
      "Epoch 287/500\n",
      "27/27 [==============================] - 0s 402us/sample - loss: 0.2816 - accuracy: 0.9630\n",
      "Epoch 288/500\n",
      "27/27 [==============================] - 0s 357us/sample - loss: 0.3182 - accuracy: 0.9630\n",
      "Epoch 289/500\n",
      "27/27 [==============================] - 0s 340us/sample - loss: 0.2192 - accuracy: 0.9630\n",
      "Epoch 290/500\n",
      "27/27 [==============================] - 0s 379us/sample - loss: 0.2400 - accuracy: 0.9259\n",
      "Epoch 291/500\n",
      "27/27 [==============================] - 0s 363us/sample - loss: 0.2369 - accuracy: 0.9630\n",
      "Epoch 292/500\n",
      "27/27 [==============================] - 0s 394us/sample - loss: 0.2577 - accuracy: 0.8889\n",
      "Epoch 293/500\n",
      "27/27 [==============================] - 0s 387us/sample - loss: 0.2010 - accuracy: 0.9630\n",
      "Epoch 294/500\n",
      "27/27 [==============================] - 0s 342us/sample - loss: 0.2362 - accuracy: 0.9259\n",
      "Epoch 295/500\n",
      "27/27 [==============================] - 0s 374us/sample - loss: 0.3630 - accuracy: 0.8889\n",
      "Epoch 296/500\n",
      "27/27 [==============================] - 0s 353us/sample - loss: 0.2242 - accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "27/27 [==============================] - 0s 342us/sample - loss: 0.1594 - accuracy: 0.9630\n",
      "Epoch 298/500\n",
      "27/27 [==============================] - 0s 392us/sample - loss: 0.2092 - accuracy: 0.9630\n",
      "Epoch 299/500\n",
      "27/27 [==============================] - 0s 353us/sample - loss: 0.4205 - accuracy: 0.7778\n",
      "Epoch 300/500\n",
      "27/27 [==============================] - 0s 440us/sample - loss: 0.3818 - accuracy: 0.8889\n",
      "Epoch 301/500\n",
      "27/27 [==============================] - 0s 448us/sample - loss: 0.3910 - accuracy: 0.8889\n",
      "Epoch 302/500\n",
      "27/27 [==============================] - 0s 395us/sample - loss: 0.1709 - accuracy: 0.9630\n",
      "Epoch 303/500\n",
      "27/27 [==============================] - 0s 377us/sample - loss: 0.3199 - accuracy: 0.9259\n",
      "Epoch 304/500\n",
      "27/27 [==============================] - 0s 372us/sample - loss: 0.1876 - accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "27/27 [==============================] - 0s 346us/sample - loss: 0.2325 - accuracy: 0.9630\n",
      "Epoch 306/500\n",
      "27/27 [==============================] - 0s 340us/sample - loss: 0.1546 - accuracy: 0.9630\n",
      "Epoch 307/500\n",
      "27/27 [==============================] - 0s 379us/sample - loss: 0.2234 - accuracy: 0.9259\n",
      "Epoch 308/500\n",
      "27/27 [==============================] - 0s 357us/sample - loss: 0.1190 - accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "27/27 [==============================] - 0s 359us/sample - loss: 0.2093 - accuracy: 0.9630\n",
      "Epoch 310/500\n",
      "27/27 [==============================] - 0s 373us/sample - loss: 0.2479 - accuracy: 0.9630\n",
      "Epoch 311/500\n",
      "27/27 [==============================] - 0s 355us/sample - loss: 0.1794 - accuracy: 0.8889\n",
      "Epoch 312/500\n",
      "27/27 [==============================] - 0s 367us/sample - loss: 0.1909 - accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "27/27 [==============================] - 0s 428us/sample - loss: 0.2087 - accuracy: 0.9630\n",
      "Epoch 314/500\n",
      "27/27 [==============================] - 0s 341us/sample - loss: 0.1833 - accuracy: 0.9630\n",
      "Epoch 315/500\n",
      "27/27 [==============================] - 0s 377us/sample - loss: 0.2477 - accuracy: 0.9259\n",
      "Epoch 316/500\n",
      "27/27 [==============================] - 0s 370us/sample - loss: 0.3177 - accuracy: 0.8889\n",
      "Epoch 317/500\n",
      "27/27 [==============================] - 0s 326us/sample - loss: 0.0782 - accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "27/27 [==============================] - 0s 364us/sample - loss: 0.2523 - accuracy: 0.8889\n",
      "Epoch 319/500\n",
      "27/27 [==============================] - 0s 343us/sample - loss: 0.2321 - accuracy: 0.9630\n",
      "Epoch 320/500\n",
      "27/27 [==============================] - 0s 371us/sample - loss: 0.1886 - accuracy: 0.9259\n",
      "Epoch 321/500\n",
      "27/27 [==============================] - 0s 358us/sample - loss: 0.4793 - accuracy: 0.7407\n",
      "Epoch 322/500\n",
      "27/27 [==============================] - 0s 377us/sample - loss: 0.1920 - accuracy: 0.9630\n",
      "Epoch 323/500\n",
      "27/27 [==============================] - 0s 354us/sample - loss: 0.3726 - accuracy: 0.8148\n",
      "Epoch 324/500\n",
      "27/27 [==============================] - 0s 397us/sample - loss: 0.1883 - accuracy: 0.9630\n",
      "Epoch 325/500\n",
      "27/27 [==============================] - 0s 397us/sample - loss: 0.1882 - accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "27/27 [==============================] - 0s 384us/sample - loss: 0.2446 - accuracy: 0.8889\n",
      "Epoch 327/500\n",
      "27/27 [==============================] - 0s 331us/sample - loss: 0.1610 - accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "27/27 [==============================] - 0s 383us/sample - loss: 0.1738 - accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "27/27 [==============================] - 0s 388us/sample - loss: 0.2589 - accuracy: 0.9630\n",
      "Epoch 330/500\n",
      "27/27 [==============================] - 0s 348us/sample - loss: 0.4465 - accuracy: 0.7778\n",
      "Epoch 331/500\n",
      "27/27 [==============================] - 0s 385us/sample - loss: 0.0948 - accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "27/27 [==============================] - 0s 381us/sample - loss: 0.1826 - accuracy: 0.9630\n",
      "Epoch 333/500\n",
      "27/27 [==============================] - 0s 423us/sample - loss: 0.1183 - accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "27/27 [==============================] - 0s 426us/sample - loss: 0.1718 - accuracy: 0.9259\n",
      "Epoch 335/500\n",
      "27/27 [==============================] - 0s 427us/sample - loss: 0.1638 - accuracy: 0.9630\n",
      "Epoch 336/500\n",
      "27/27 [==============================] - 0s 403us/sample - loss: 0.4166 - accuracy: 0.8889\n",
      "Epoch 337/500\n",
      "27/27 [==============================] - 0s 424us/sample - loss: 0.1269 - accuracy: 0.9630\n",
      "Epoch 338/500\n",
      "27/27 [==============================] - 0s 474us/sample - loss: 0.2235 - accuracy: 0.9630\n",
      "Epoch 339/500\n",
      "27/27 [==============================] - 0s 413us/sample - loss: 0.2265 - accuracy: 0.9259\n",
      "Epoch 340/500\n",
      "27/27 [==============================] - 0s 406us/sample - loss: 0.2255 - accuracy: 0.9259\n",
      "Epoch 341/500\n",
      "27/27 [==============================] - 0s 401us/sample - loss: 0.1825 - accuracy: 0.9630\n",
      "Epoch 342/500\n",
      "27/27 [==============================] - 0s 408us/sample - loss: 0.1667 - accuracy: 0.9630\n",
      "Epoch 343/500\n",
      "27/27 [==============================] - 0s 494us/sample - loss: 0.1680 - accuracy: 0.9630\n",
      "Epoch 344/500\n",
      "27/27 [==============================] - 0s 411us/sample - loss: 0.2159 - accuracy: 0.9259\n",
      "Epoch 345/500\n",
      "27/27 [==============================] - 0s 422us/sample - loss: 0.2336 - accuracy: 0.9630\n",
      "Epoch 346/500\n",
      "27/27 [==============================] - 0s 409us/sample - loss: 0.1844 - accuracy: 0.9630\n",
      "Epoch 347/500\n",
      "27/27 [==============================] - 0s 384us/sample - loss: 0.2221 - accuracy: 0.9259\n",
      "Epoch 348/500\n",
      "27/27 [==============================] - 0s 386us/sample - loss: 0.1186 - accuracy: 0.9630\n",
      "Epoch 349/500\n",
      "27/27 [==============================] - 0s 353us/sample - loss: 0.0305 - accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "27/27 [==============================] - 0s 333us/sample - loss: 0.1681 - accuracy: 0.9630\n",
      "Epoch 351/500\n",
      "27/27 [==============================] - 0s 369us/sample - loss: 0.1454 - accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "27/27 [==============================] - 0s 391us/sample - loss: 0.1797 - accuracy: 0.9259\n",
      "Epoch 353/500\n",
      "27/27 [==============================] - 0s 341us/sample - loss: 0.1728 - accuracy: 0.9259\n",
      "Epoch 354/500\n",
      "27/27 [==============================] - 0s 392us/sample - loss: 0.1195 - accuracy: 0.9630\n",
      "Epoch 355/500\n",
      "27/27 [==============================] - 0s 380us/sample - loss: 0.0917 - accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "27/27 [==============================] - 0s 371us/sample - loss: 0.2583 - accuracy: 0.9259\n",
      "Epoch 357/500\n",
      "27/27 [==============================] - 0s 442us/sample - loss: 0.0832 - accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "27/27 [==============================] - 0s 445us/sample - loss: 0.1215 - accuracy: 0.9630\n",
      "Epoch 359/500\n",
      "27/27 [==============================] - 0s 445us/sample - loss: 0.2581 - accuracy: 0.9259\n",
      "Epoch 360/500\n",
      "27/27 [==============================] - 0s 441us/sample - loss: 0.1149 - accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "27/27 [==============================] - 0s 417us/sample - loss: 0.2948 - accuracy: 0.8889\n",
      "Epoch 362/500\n",
      "27/27 [==============================] - 0s 421us/sample - loss: 0.2414 - accuracy: 0.9259\n",
      "Epoch 363/500\n",
      "27/27 [==============================] - 0s 421us/sample - loss: 0.1468 - accuracy: 0.9630\n",
      "Epoch 364/500\n",
      "27/27 [==============================] - 0s 435us/sample - loss: 0.1971 - accuracy: 0.9630\n",
      "Epoch 365/500\n",
      "27/27 [==============================] - 0s 435us/sample - loss: 0.1686 - accuracy: 0.9630\n",
      "Epoch 366/500\n",
      "27/27 [==============================] - 0s 472us/sample - loss: 0.2313 - accuracy: 0.9259\n",
      "Epoch 367/500\n",
      "27/27 [==============================] - 0s 393us/sample - loss: 0.1967 - accuracy: 0.9630\n",
      "Epoch 368/500\n",
      "27/27 [==============================] - 0s 436us/sample - loss: 0.0891 - accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "27/27 [==============================] - 0s 545us/sample - loss: 0.1898 - accuracy: 0.9259\n",
      "Epoch 370/500\n",
      "27/27 [==============================] - 0s 367us/sample - loss: 0.2040 - accuracy: 0.9259\n",
      "Epoch 371/500\n",
      "27/27 [==============================] - 0s 346us/sample - loss: 0.2103 - accuracy: 0.9259\n",
      "Epoch 372/500\n",
      "27/27 [==============================] - 0s 441us/sample - loss: 0.1453 - accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "27/27 [==============================] - 0s 420us/sample - loss: 0.0685 - accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "27/27 [==============================] - 0s 344us/sample - loss: 0.2602 - accuracy: 0.9259\n",
      "Epoch 375/500\n",
      "27/27 [==============================] - 0s 467us/sample - loss: 0.2591 - accuracy: 0.9630\n",
      "Epoch 376/500\n",
      "27/27 [==============================] - 0s 374us/sample - loss: 0.0951 - accuracy: 0.9630\n",
      "Epoch 377/500\n",
      "27/27 [==============================] - 0s 336us/sample - loss: 0.3008 - accuracy: 0.8889\n",
      "Epoch 378/500\n",
      "27/27 [==============================] - 0s 454us/sample - loss: 0.1119 - accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "27/27 [==============================] - 0s 379us/sample - loss: 0.0978 - accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "27/27 [==============================] - 0s 400us/sample - loss: 0.2792 - accuracy: 0.9630\n",
      "Epoch 381/500\n",
      "27/27 [==============================] - 0s 517us/sample - loss: 0.1516 - accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "27/27 [==============================] - 0s 388us/sample - loss: 0.1504 - accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "27/27 [==============================] - 0s 359us/sample - loss: 0.1818 - accuracy: 0.9630\n",
      "Epoch 384/500\n",
      "27/27 [==============================] - 0s 445us/sample - loss: 0.2227 - accuracy: 0.9630\n",
      "Epoch 385/500\n",
      "27/27 [==============================] - 0s 386us/sample - loss: 0.0764 - accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "27/27 [==============================] - 0s 384us/sample - loss: 0.2425 - accuracy: 0.9259\n",
      "Epoch 387/500\n",
      "27/27 [==============================] - 0s 382us/sample - loss: 0.2126 - accuracy: 0.9259\n",
      "Epoch 388/500\n",
      "27/27 [==============================] - 0s 373us/sample - loss: 0.1952 - accuracy: 0.9259\n",
      "Epoch 389/500\n",
      "27/27 [==============================] - 0s 459us/sample - loss: 0.1701 - accuracy: 0.9630\n",
      "Epoch 390/500\n",
      "27/27 [==============================] - 0s 450us/sample - loss: 0.1569 - accuracy: 0.9630\n",
      "Epoch 391/500\n",
      "27/27 [==============================] - 0s 420us/sample - loss: 0.1266 - accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "27/27 [==============================] - 0s 481us/sample - loss: 0.1594 - accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "27/27 [==============================] - 0s 416us/sample - loss: 0.2264 - accuracy: 0.8889\n",
      "Epoch 394/500\n",
      "27/27 [==============================] - 0s 465us/sample - loss: 0.2635 - accuracy: 0.8519\n",
      "Epoch 395/500\n",
      "27/27 [==============================] - 0s 363us/sample - loss: 0.2558 - accuracy: 0.9259\n",
      "Epoch 396/500\n",
      "27/27 [==============================] - 0s 358us/sample - loss: 0.1020 - accuracy: 0.9630\n",
      "Epoch 397/500\n",
      "27/27 [==============================] - 0s 388us/sample - loss: 0.1321 - accuracy: 0.9630\n",
      "Epoch 398/500\n",
      "27/27 [==============================] - 0s 398us/sample - loss: 0.0974 - accuracy: 0.9630\n",
      "Epoch 399/500\n",
      "27/27 [==============================] - 0s 460us/sample - loss: 0.3120 - accuracy: 0.9259\n",
      "Epoch 400/500\n",
      "27/27 [==============================] - 0s 479us/sample - loss: 0.1396 - accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "27/27 [==============================] - 0s 392us/sample - loss: 0.0669 - accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "27/27 [==============================] - 0s 394us/sample - loss: 0.2268 - accuracy: 0.9259\n",
      "Epoch 403/500\n",
      "27/27 [==============================] - 0s 501us/sample - loss: 0.0693 - accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "27/27 [==============================] - 0s 391us/sample - loss: 0.2414 - accuracy: 0.8519\n",
      "Epoch 405/500\n",
      "27/27 [==============================] - 0s 471us/sample - loss: 0.0676 - accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "27/27 [==============================] - 0s 410us/sample - loss: 0.2437 - accuracy: 0.9630\n",
      "Epoch 407/500\n",
      "27/27 [==============================] - 0s 356us/sample - loss: 0.2903 - accuracy: 0.8889\n",
      "Epoch 408/500\n",
      "27/27 [==============================] - 0s 381us/sample - loss: 0.2870 - accuracy: 0.8889\n",
      "Epoch 409/500\n",
      "27/27 [==============================] - 0s 396us/sample - loss: 0.1747 - accuracy: 0.9630\n",
      "Epoch 410/500\n",
      "27/27 [==============================] - 0s 388us/sample - loss: 0.2062 - accuracy: 0.9630\n",
      "Epoch 411/500\n",
      "27/27 [==============================] - 0s 341us/sample - loss: 0.1787 - accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "27/27 [==============================] - 0s 430us/sample - loss: 0.2123 - accuracy: 0.8889\n",
      "Epoch 413/500\n",
      "27/27 [==============================] - 0s 373us/sample - loss: 0.1281 - accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "27/27 [==============================] - 0s 443us/sample - loss: 0.1926 - accuracy: 0.9259\n",
      "Epoch 415/500\n",
      "27/27 [==============================] - 0s 374us/sample - loss: 0.2404 - accuracy: 0.9630\n",
      "Epoch 416/500\n",
      "27/27 [==============================] - 0s 442us/sample - loss: 0.0694 - accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "27/27 [==============================] - 0s 379us/sample - loss: 0.1155 - accuracy: 0.9630\n",
      "Epoch 418/500\n",
      "27/27 [==============================] - 0s 342us/sample - loss: 0.2172 - accuracy: 0.8889\n",
      "Epoch 419/500\n",
      "27/27 [==============================] - 0s 366us/sample - loss: 0.1049 - accuracy: 0.9630\n",
      "Epoch 420/500\n",
      "27/27 [==============================] - 0s 371us/sample - loss: 0.0398 - accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "27/27 [==============================] - 0s 369us/sample - loss: 0.0947 - accuracy: 0.9630\n",
      "Epoch 422/500\n",
      "27/27 [==============================] - 0s 439us/sample - loss: 0.1836 - accuracy: 0.9630\n",
      "Epoch 423/500\n",
      "27/27 [==============================] - 0s 395us/sample - loss: 0.1378 - accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "27/27 [==============================] - 0s 374us/sample - loss: 0.2351 - accuracy: 0.9630\n",
      "Epoch 425/500\n",
      "27/27 [==============================] - 0s 404us/sample - loss: 0.2000 - accuracy: 0.9259\n",
      "Epoch 426/500\n",
      "27/27 [==============================] - 0s 382us/sample - loss: 0.0641 - accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "27/27 [==============================] - 0s 343us/sample - loss: 0.3580 - accuracy: 0.8519\n",
      "Epoch 428/500\n",
      "27/27 [==============================] - 0s 455us/sample - loss: 0.1930 - accuracy: 0.9259\n",
      "Epoch 429/500\n",
      "27/27 [==============================] - 0s 381us/sample - loss: 0.0867 - accuracy: 0.9630\n",
      "Epoch 430/500\n",
      "27/27 [==============================] - 0s 356us/sample - loss: 0.0941 - accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "27/27 [==============================] - 0s 421us/sample - loss: 0.0856 - accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "27/27 [==============================] - 0s 402us/sample - loss: 0.1272 - accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "27/27 [==============================] - 0s 347us/sample - loss: 0.1853 - accuracy: 0.9259\n",
      "Epoch 434/500\n",
      "27/27 [==============================] - 0s 489us/sample - loss: 0.2125 - accuracy: 0.9259\n",
      "Epoch 435/500\n",
      "27/27 [==============================] - 0s 417us/sample - loss: 0.2466 - accuracy: 0.8889\n",
      "Epoch 436/500\n",
      "27/27 [==============================] - 0s 375us/sample - loss: 0.1760 - accuracy: 0.9630\n",
      "Epoch 437/500\n",
      "27/27 [==============================] - 0s 482us/sample - loss: 0.0826 - accuracy: 0.9630\n",
      "Epoch 438/500\n",
      "27/27 [==============================] - 0s 386us/sample - loss: 0.1546 - accuracy: 0.9630\n",
      "Epoch 439/500\n",
      "27/27 [==============================] - 0s 448us/sample - loss: 0.1748 - accuracy: 0.9630\n",
      "Epoch 440/500\n",
      "27/27 [==============================] - 0s 376us/sample - loss: 0.3890 - accuracy: 0.8148\n",
      "Epoch 441/500\n",
      "27/27 [==============================] - 0s 374us/sample - loss: 0.0656 - accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "27/27 [==============================] - 0s 376us/sample - loss: 0.1821 - accuracy: 0.9630\n",
      "Epoch 443/500\n",
      "27/27 [==============================] - 0s 427us/sample - loss: 0.1438 - accuracy: 0.9259\n",
      "Epoch 444/500\n",
      "27/27 [==============================] - 0s 555us/sample - loss: 0.0669 - accuracy: 0.9630\n",
      "Epoch 445/500\n",
      "27/27 [==============================] - 0s 429us/sample - loss: 0.1643 - accuracy: 0.9259\n",
      "Epoch 446/500\n",
      "27/27 [==============================] - 0s 410us/sample - loss: 0.1015 - accuracy: 0.9630\n",
      "Epoch 447/500\n",
      "27/27 [==============================] - 0s 406us/sample - loss: 0.0717 - accuracy: 0.9630\n",
      "Epoch 448/500\n",
      "27/27 [==============================] - 0s 505us/sample - loss: 0.2125 - accuracy: 0.9630\n",
      "Epoch 449/500\n",
      "27/27 [==============================] - 0s 401us/sample - loss: 0.2086 - accuracy: 0.9630\n",
      "Epoch 450/500\n",
      "27/27 [==============================] - 0s 357us/sample - loss: 0.0533 - accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "27/27 [==============================] - 0s 423us/sample - loss: 0.1627 - accuracy: 0.9630\n",
      "Epoch 452/500\n",
      "27/27 [==============================] - 0s 395us/sample - loss: 0.1300 - accuracy: 0.9630\n",
      "Epoch 453/500\n",
      "27/27 [==============================] - 0s 391us/sample - loss: 0.2117 - accuracy: 0.9259\n",
      "Epoch 454/500\n",
      "27/27 [==============================] - 0s 449us/sample - loss: 0.0871 - accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "27/27 [==============================] - 0s 385us/sample - loss: 0.0849 - accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "27/27 [==============================] - 0s 401us/sample - loss: 0.1903 - accuracy: 0.9630\n",
      "Epoch 457/500\n",
      "27/27 [==============================] - 0s 380us/sample - loss: 0.0655 - accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "27/27 [==============================] - 0s 380us/sample - loss: 0.1676 - accuracy: 0.9259\n",
      "Epoch 459/500\n",
      "27/27 [==============================] - 0s 433us/sample - loss: 0.2290 - accuracy: 0.9259\n",
      "Epoch 460/500\n",
      "27/27 [==============================] - 0s 367us/sample - loss: 0.1695 - accuracy: 0.9259\n",
      "Epoch 461/500\n",
      "27/27 [==============================] - 0s 368us/sample - loss: 0.0764 - accuracy: 0.9630\n",
      "Epoch 462/500\n",
      "27/27 [==============================] - 0s 414us/sample - loss: 0.0498 - accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "27/27 [==============================] - 0s 384us/sample - loss: 0.1487 - accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "27/27 [==============================] - 0s 350us/sample - loss: 0.0635 - accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "27/27 [==============================] - 0s 358us/sample - loss: 0.1130 - accuracy: 0.9630\n",
      "Epoch 466/500\n",
      "27/27 [==============================] - 0s 369us/sample - loss: 0.1462 - accuracy: 0.9630\n",
      "Epoch 467/500\n",
      "27/27 [==============================] - 0s 373us/sample - loss: 0.0487 - accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "27/27 [==============================] - 0s 383us/sample - loss: 0.0429 - accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "27/27 [==============================] - 0s 375us/sample - loss: 0.0968 - accuracy: 0.9630\n",
      "Epoch 470/500\n",
      "27/27 [==============================] - 0s 368us/sample - loss: 0.1536 - accuracy: 0.9259\n",
      "Epoch 471/500\n",
      "27/27 [==============================] - 0s 418us/sample - loss: 0.2215 - accuracy: 0.9259\n",
      "Epoch 472/500\n",
      "27/27 [==============================] - 0s 402us/sample - loss: 0.1037 - accuracy: 0.9630\n",
      "Epoch 473/500\n",
      "27/27 [==============================] - 0s 408us/sample - loss: 0.1756 - accuracy: 0.9259\n",
      "Epoch 474/500\n",
      "27/27 [==============================] - 0s 360us/sample - loss: 0.1304 - accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "27/27 [==============================] - 0s 444us/sample - loss: 0.1318 - accuracy: 0.9630\n",
      "Epoch 476/500\n",
      "27/27 [==============================] - 0s 392us/sample - loss: 0.1333 - accuracy: 0.9259\n",
      "Epoch 477/500\n",
      "27/27 [==============================] - 0s 377us/sample - loss: 0.3581 - accuracy: 0.8519\n",
      "Epoch 478/500\n",
      "27/27 [==============================] - 0s 382us/sample - loss: 0.1206 - accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "27/27 [==============================] - 0s 409us/sample - loss: 0.1292 - accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "27/27 [==============================] - 0s 376us/sample - loss: 0.2022 - accuracy: 0.8889\n",
      "Epoch 481/500\n",
      "27/27 [==============================] - 0s 378us/sample - loss: 0.3235 - accuracy: 0.8889\n",
      "Epoch 482/500\n",
      "27/27 [==============================] - 0s 440us/sample - loss: 0.1111 - accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "27/27 [==============================] - 0s 396us/sample - loss: 0.1911 - accuracy: 0.9630\n",
      "Epoch 484/500\n",
      "27/27 [==============================] - 0s 401us/sample - loss: 0.1935 - accuracy: 0.9630\n",
      "Epoch 485/500\n",
      "27/27 [==============================] - 0s 343us/sample - loss: 0.1387 - accuracy: 0.9259\n",
      "Epoch 486/500\n",
      "27/27 [==============================] - 0s 419us/sample - loss: 0.0726 - accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "27/27 [==============================] - 0s 408us/sample - loss: 0.1099 - accuracy: 0.9630\n",
      "Epoch 488/500\n",
      "27/27 [==============================] - 0s 334us/sample - loss: 0.1767 - accuracy: 0.9630\n",
      "Epoch 489/500\n",
      "27/27 [==============================] - 0s 395us/sample - loss: 0.1297 - accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "27/27 [==============================] - 0s 404us/sample - loss: 0.1447 - accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "27/27 [==============================] - 0s 329us/sample - loss: 0.1862 - accuracy: 0.9630\n",
      "Epoch 492/500\n",
      "27/27 [==============================] - 0s 449us/sample - loss: 0.0504 - accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "27/27 [==============================] - 0s 466us/sample - loss: 0.0981 - accuracy: 0.9630\n",
      "Epoch 494/500\n",
      "27/27 [==============================] - 0s 337us/sample - loss: 0.2717 - accuracy: 0.8519\n",
      "Epoch 495/500\n",
      "27/27 [==============================] - 0s 474us/sample - loss: 0.1149 - accuracy: 0.9259\n",
      "Epoch 496/500\n",
      "27/27 [==============================] - 0s 426us/sample - loss: 0.0677 - accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "27/27 [==============================] - 0s 399us/sample - loss: 0.2115 - accuracy: 0.9630\n",
      "Epoch 498/500\n",
      "27/27 [==============================] - 0s 441us/sample - loss: 0.1309 - accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "27/27 [==============================] - 0s 413us/sample - loss: 0.2699 - accuracy: 0.8889\n",
      "Epoch 500/500\n",
      "27/27 [==============================] - 0s 438us/sample - loss: 0.2437 - accuracy: 0.8889\n"
     ]
    }
   ],
   "source": [
    "cb.model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb.model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb.model.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 48)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=np.reshape(test,(1,48))\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=cb.model.ann.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.14796011e-09 1.16214025e-07 3.47157822e-07 9.99977350e-01\n",
      "  1.16851879e-06 6.39009886e-06 1.04172295e-05 3.39423173e-06\n",
      "  8.38683832e-07]]\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "idclass=np.argmax(p)\n",
    "print(idclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mopeds\n"
     ]
    }
   ],
   "source": [
    "print(cb.model.classes[idclass])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.utils  import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 25)                700       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 234       \n",
      "=================================================================\n",
      "Total params: 1,584\n",
      "Trainable params: 1,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=27))          # densidad de la primera capa de neurona y tipo de entrada\n",
    "model.add(Dropout(0.5))                                        # convierte a 0 la mitad de 1 en el entrenamiento\n",
    "model.add(Dense(25))                                           # densidad de la primera capa de neurona\n",
    "model.add(Dropout(0.5))                                        # convierte a 0 la mitad de 1 en el entrenamiento\n",
    "model.add(Dense(9, activation='softmax'))  # densidad de la salida\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
